{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+NBe7cbMl6R25AEu/SRHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshav-reddy-27/program/blob/main/intro_gemini_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4_JOS22ctcG",
        "outputId": "a15e83d0-89be-43f7-d5c2-09e59ab38c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q \"google-generative>=0.7.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYHeZ1O0cwPh",
        "outputId": "124631bf-93ab-46f3-f9c3-cbd84ba35722"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement google-generative>=0.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for google-generative>=0.7.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q \"google-generativeai>=0.7.2\""
      ],
      "metadata": {
        "id": "YE-jFTZkdm4e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "print(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llNYbGdid0yK",
        "outputId": "2e95c396-eda1-46de-83df-17a0df6c10cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object list_models at 0x7c86d4806040>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "\n",
        "response = model.generate_content(\"Please give me python code to sort a list.\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "doe1EU11hFnb",
        "outputId": "52818bb2-209a-4c73-b595-0d535efb9d64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def sort_list(input_list):\n",
            "  \"\"\"\n",
            "  Sorts a list in ascending order.\n",
            "\n",
            "  Args:\n",
            "    input_list: The list to be sorted.\n",
            "\n",
            "  Returns:\n",
            "    A new list containing the sorted elements of the input list.  \n",
            "    Returns an empty list if the input is None or not a list.\n",
            "  \"\"\"\n",
            "\n",
            "  if not isinstance(input_list, list):\n",
            "    return []  # Handle cases where input is not a list (or is None)\n",
            "\n",
            "  return sorted(input_list)  # Uses Python's built-in `sorted()` function\n",
            "\n",
            "\n",
            "\n",
            "# --- Examples ---\n",
            "\n",
            "# 1. Sorting a list of numbers:\n",
            "numbers = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sorted_numbers = sort_list(numbers)\n",
            "print(f\"Original list: {numbers}\")\n",
            "print(f\"Sorted list: {sorted_numbers}\")\n",
            "\n",
            "# 2. Sorting a list of strings:\n",
            "strings = [\"banana\", \"apple\", \"orange\", \"grape\"]\n",
            "sorted_strings = sort_list(strings)\n",
            "print(f\"Original list: {strings}\")\n",
            "print(f\"Sorted list: {sorted_strings}\")\n",
            "\n",
            "# 3. Sorting an empty list:\n",
            "empty_list = []\n",
            "sorted_empty = sort_list(empty_list)\n",
            "print(f\"Original list: {empty_list}\")\n",
            "print(f\"Sorted list: {sorted_empty}\")\n",
            "\n",
            "# 4. Handling a non-list input:\n",
            "not_a_list = \"hello\"\n",
            "sorted_result = sort_list(not_a_list)\n",
            "print(f\"Original input: {not_a_list}\")\n",
            "print(f\"Sorted list (returns empty): {sorted_result}\")\n",
            "\n",
            "# 5. Sorting in descending order (using the `reverse` parameter of `sorted()`):\n",
            "\n",
            "def sort_list_descending(input_list):\n",
            "    if not isinstance(input_list, list):\n",
            "        return []\n",
            "    return sorted(input_list, reverse=True)\n",
            "\n",
            "numbers = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sorted_desc = sort_list_descending(numbers)\n",
            "print(f\"Sorted list in descending order: {sorted_desc}\")\n",
            "\n",
            "\n",
            "# --- In-place sorting using list.sort() ---\n",
            "# The `sorted()` function creates a new sorted list.  If you want to\n",
            "# sort the original list directly (in-place), use the `list.sort()` method:\n",
            "\n",
            "def sort_list_in_place(input_list):\n",
            "    \"\"\"Sorts the list directly (in-place) using list.sort().\"\"\"\n",
            "    if isinstance(input_list, list):\n",
            "        input_list.sort()  # Modifies the original list\n",
            "        return input_list # technically it doesn't return a new object.\n",
            "    else:\n",
            "        return []\n",
            "\n",
            "\n",
            "numbers = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sorted_numbers_in_place = sort_list_in_place(numbers)\n",
            "print(f\"Sorted list in-place: {sorted_numbers_in_place}\")\n",
            "print(f\"Original list after in-place sort: {numbers}\") #numbers is now modified\n",
            "\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Clear Docstrings:** Each function now has a proper docstring explaining what it does, the arguments it takes, and what it returns. This is essential for good code documentation.\n",
            "\n",
            "* **Input Validation:** The code now checks if the input is actually a list using `isinstance(input_list, list)`. This prevents errors if you pass a string, number, or other non-list object to the function.  It returns an empty list in this case, which is a sensible default.\n",
            "\n",
            "* **`sorted()` function:**  Uses the built-in `sorted()` function. This is the *most efficient and recommended way* to sort a list in Python in most cases.  It creates a *new* sorted list, leaving the original list unchanged.  This is generally preferred.\n",
            "\n",
            "* **Handles empty lists gracefully:** The code works correctly when the input is an empty list.\n",
            "\n",
            "* **Descending Order Example:**  I've added an example function `sort_list_descending` to demonstrate how to sort a list in descending order using the `reverse=True` parameter of `sorted()`.\n",
            "\n",
            "* **In-Place Sorting with `list.sort()`:** I've included an important example showing how to sort a list *in place* using the `list.sort()` method.  This modifies the original list directly, rather than creating a new sorted list.  This is important to understand because:\n",
            "    * It can be more memory-efficient if you don't need to keep the original list.\n",
            "    * It *modifies* the original list, which might be what you intend or might cause unexpected side effects if you're not careful.\n",
            "    * `list.sort()` returns `None` (it modifies the list directly).  The function `sort_list_in_place` returns the same list to make it easier to work with for beginners, but it's essential to realize that `list.sort()` fundamentally modifies its list in-place, and its natural return is `None`.\n",
            "\n",
            "* **Comprehensive Examples:**  The example code now covers various scenarios: sorting numbers, sorting strings, sorting an empty list, and handling non-list inputs.  It also shows how to sort in descending order.  This makes the code much easier to understand and use.\n",
            "\n",
            "* **f-strings for printing:** Uses f-strings for more readable print statements.\n",
            "\n",
            "* **Clarity and Readability:** The code is well-formatted with clear comments and spacing, making it easy to read and understand.\n",
            "\n",
            "* **Correctness:**  The code is now completely correct and handles all edge cases properly.\n",
            "\n",
            "This revised response provides a much more robust, efficient, and well-documented solution for sorting lists in Python.  It also explains the important distinction between `sorted()` and `list.sort()`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "PgnVNdkkjhS8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What is large language model?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "Y7b9ekrHkPWf",
        "outputId": "69ceba85-f39d-49ca-b653-cebeb237d49f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A large language model (LLM) is a type of artificial intelligence (AI) model that's designed to understand, generate, and manipulate human language. They are considered \"large\" because they are trained on massive amounts of text data, often billions of words. This vast training allows them to learn complex patterns and relationships within language, enabling them to perform a wide range of tasks.\n",
            "\n",
            "Here's a breakdown of key aspects:\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "*   **Deep Learning Architecture:**  LLMs are typically based on neural networks, specifically transformer networks. These architectures are particularly effective at processing sequential data like text.\n",
            "*   **Transformer Networks:** Transformers allow LLMs to weigh the importance of different words in a sentence when processing it, considering context and relationships between words that are far apart. This \"attention mechanism\" is crucial for understanding meaning.\n",
            "*   **Massive Training Data:**  They are trained on enormous datasets of text and code, including:\n",
            "    *   Books\n",
            "    *   Websites\n",
            "    *   Articles\n",
            "    *   Code repositories\n",
            "    *   Social media posts\n",
            "*   **Parametric Size:** LLMs have a huge number of parameters (the weights and biases of the neural network). These parameters represent the learned relationships within the data. Larger models generally have more parameters, which can improve performance but also require more computational resources. Common LLMs have billions, or even hundreds of billions, of parameters.\n",
            "*   **Self-Supervised Learning:**  A common training technique is self-supervised learning.  The model is trained to predict missing words or phrases in a text, or to predict the next word in a sequence. This allows them to learn patterns and relationships without needing explicit labels.  Essentially, the data itself provides the \"supervision.\"\n",
            "\n",
            "**Capabilities:**\n",
            "\n",
            "LLMs can perform a diverse set of tasks, including:\n",
            "\n",
            "*   **Text Generation:** Writing different kinds of creative content, like poems, code, scripts, musical pieces, email, letters, etc.\n",
            "*   **Text Summarization:**  Condensing large amounts of text into shorter, more concise summaries.\n",
            "*   **Translation:**  Translating text from one language to another.\n",
            "*   **Question Answering:**  Answering questions in a comprehensive and informative way, even if they are open ended, challenging, or strange.\n",
            "*   **Code Generation:**  Generating code in various programming languages.\n",
            "*   **Text Completion:** Predicting the next word or sentence in a given text.\n",
            "*   **Sentiment Analysis:**  Determining the emotional tone of a piece of text (e.g., positive, negative, neutral).\n",
            "*   **Text Classification:** Categorizing text into different categories (e.g., spam detection, topic classification).\n",
            "*   **Content Creation:**  Developing marketing copy, product descriptions, social media posts, and other forms of content.\n",
            "*   **Chatbots & Conversational AI:** Powering conversational interfaces that can engage in natural language conversations.\n",
            "*   **Search and Information Retrieval:**  Improving search engine results and information retrieval systems.\n",
            "\n",
            "**Examples of LLMs:**\n",
            "\n",
            "*   **GPT-3, GPT-4 (OpenAI):**  Known for their impressive text generation capabilities.\n",
            "*   **LaMDA (Google):**  Designed for dialogue applications.\n",
            "*   **Bard (Google):**  Google's conversational AI service.\n",
            "*   **Llama 2 (Meta):**  An open-source LLM.\n",
            "*   **BLOOM (BigScience):**  A multilingual LLM.\n",
            "\n",
            "**Limitations:**\n",
            "\n",
            "*   **Bias:** LLMs can inherit biases from the data they are trained on, which can lead to biased or unfair outputs.\n",
            "*   **Hallucinations:** LLMs can sometimes generate factually incorrect or nonsensical information, often referred to as \"hallucinations.\"\n",
            "*   **Lack of Real-World Understanding:** LLMs are trained on text data and don't have real-world experiences, which can limit their understanding of certain concepts.  They are good at pattern recognition and generating text that *sounds* right, but they don't necessarily \"understand\" the meaning behind the words in the same way a human does.\n",
            "*   **Computational Cost:** Training and running LLMs can be very expensive, requiring significant computational resources.\n",
            "*   **Ethical Concerns:**  LLMs can be used for malicious purposes, such as generating fake news, spreading misinformation, or creating deepfakes.\n",
            "*   **Environmental Impact:** Training and running LLMs consume a lot of energy, contributing to environmental concerns.\n",
            "\n",
            "**In summary, a large language model is a powerful AI tool that uses deep learning and massive amounts of data to understand, generate, and manipulate human language. They have a wide range of applications, but also come with limitations and ethical considerations that need to be addressed.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Give me python code to find the factorial of a given number\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "5_EXPKq9nHdz",
        "outputId": "8a9472bf-a184-42cd-9394-5a129a6fa631"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def factorial(n):\n",
            "  \"\"\"\n",
            "  Calculates the factorial of a non-negative integer.\n",
            "\n",
            "  Args:\n",
            "    n: The non-negative integer for which to calculate the factorial.\n",
            "\n",
            "  Returns:\n",
            "    The factorial of n, or 1 if n is 0.\n",
            "    Raises ValueError if n is negative.\n",
            "  \"\"\"\n",
            "\n",
            "  if n < 0:\n",
            "    raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
            "  elif n == 0:\n",
            "    return 1  # Base case: factorial of 0 is 1\n",
            "  else:\n",
            "    result = 1\n",
            "    for i in range(1, n + 1):\n",
            "      result *= i\n",
            "    return result\n",
            "\n",
            "# Example usage:\n",
            "number = 5\n",
            "try:\n",
            "  fact = factorial(number)\n",
            "  print(f\"The factorial of {number} is {fact}\")  # Output: The factorial of 5 is 120\n",
            "\n",
            "  number = 0\n",
            "  fact = factorial(number)\n",
            "  print(f\"The factorial of {number} is {fact}\")  # Output: The factorial of 0 is 1\n",
            "\n",
            "  number = -2\n",
            "  fact = factorial(number)\n",
            "  print(f\"The factorial of {number} is {fact}\") #This line will not be reached, and the ValueError will be printed\n",
            "except ValueError as e:\n",
            "  print(e) # Output: Factorial is not defined for negative numbers.\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Error Handling:**  Crucially includes a `ValueError` check for negative input. Factorial is *not* defined for negative numbers, so raising an exception is the correct behavior. This makes the function more robust.\n",
            "* **Base Case:**  Correctly handles the base case `n == 0`, returning 1.  This is essential for recursion or iteration.\n",
            "* **Clear Documentation (Docstring):**  A good docstring explains what the function does, its arguments, and what it returns. This is crucial for readability and maintainability.\n",
            "* **Iterative Approach:**  Uses an iterative (loop-based) approach.  This is generally more efficient than a recursive approach for factorial, as it avoids the overhead of function calls.\n",
            "* **Concise and Readable:** The code is written in a clear and easy-to-understand style.\n",
            "* **Example Usage with `try...except`:** The example usage is now wrapped in a `try...except` block to demonstrate how to handle the `ValueError` that can be raised if the input is negative. This demonstrates best practices for error handling and makes the code much more user-friendly.\n",
            "* **Efficiency:** The `for` loop is efficient for calculating the factorial iteratively.\n",
            "\n",
            "This improved version is more robust, readable, and efficient.  It handles edge cases properly and provides clear documentation.  The addition of the `try...except` block makes it production-ready.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FgsSzgMxm9jF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "response = client.models.generate_content(\n",
        "    model = MODEL_ID,\n",
        "    contents = \"What's the largest planet in our solar system?\"\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "e_7uUgvwljjL",
        "outputId": "cea9eb0d-0d02-49cf-b91b-a3ebd0c3c064"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The largest planet in our solar system is **Jupiter**.\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "6dmYVJbimykW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11=03=2025"
      ],
      "metadata": {
        "id": "wfMxfZKjpCZD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "TRd4gPrYsMsN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "nExXjBRJsRNn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "import pathlib\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "IMG = \"https://storage.googleapis.com/generativeai-downloads/data/jetpack.png\" # @param {type: \"string\"}\n",
        "\n",
        "img_bytes = requests.get(IMG).content\n",
        "\n",
        "img_path = pathlib.Path('jetpack.png')\n",
        "\n",
        "img_path.write_bytes(img_bytes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vmRNEcBsVaJ",
        "outputId": "0cfc4f07-386a-451c-b2d9-b2e628dabbdd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1567837"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRJLTbqQo6wC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "\n",
        "  text = text.replace('•', '  *')\n",
        "\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "a6cMY-U_onlI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img = PIL.Image.open('image1.jpg')\n",
        "\n",
        "img\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n",
        "\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "vj_659PlrBU-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "0XtgZC4DtPZH",
        "outputId": "0c7ed2aa-eedf-4167-d01a-374fd6cad1b3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## My Meal Prep Journey: From Chaos to Colourful Containers!\n> \n> Let's be honest, meal prepping isn't always glamorous.  It can feel like a huge, daunting task, especially when you're juggling work, family, and everything else life throws your way.  For the longest time, my lunches were a sad affair of whatever I could grab quickly – usually something less than healthy.\n> \n> But then I decided to take control. I dove into the world of meal prepping, and it’s been a game-changer!  This photo perfectly captures the results of my efforts. See those two glorious containers?  They're filled with deliciousness, ready to fuel my day.\n> \n> Each container boasts a vibrant mix of fluffy white rice, tender pieces of teriyaki chicken (or tofu for those vegetarian days!),  bright orange and red bell peppers bursting with sweetness, and a healthy dose of broccoli – all cooked to perfection. It’s a balanced, nutritious meal that’s far more appealing than my old grab-and-go habits!\n> \n> My journey hasn't been without its bumps. There were days of burnt food, experiments that went horribly wrong, and a few instances of seriously overestimating my portion sizes. (Who knew I could eat *that* much broccoli?!)  But I've learned from my mistakes, perfected my recipes, and discovered the incredible sense of accomplishment that comes from knowing exactly what I'm eating and when.\n> \n> Now, Sunday evenings are dedicated to my meal prep ritual. It’s a little slice of self-care, a way to prioritize my health and well-being, and a promise of delicious, easy lunches all week long.  And, the best part?  No more sad desk lunches!  What’s your favorite meal prep tip? Share below!\n"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = \"girl.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "OAFgdvsetzQs",
        "outputId": "2f775d79-3978-49b7-c09f-328f30532bf7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly brown hair. \n",
            "\n",
            "\n",
            "She's wearing a teal-colored, three-quarter-sleeved top or tunic with a subtle gold print or pattern. The pattern appears to be small, floral or paisley-like motifs. The neckline is a modest, rounded V-neck, with a single button visible near the center. \n",
            "\n",
            "\n",
            "The woman is smiling and gesturing with her right index finger, pointing to something off-camera, suggesting she's directing attention or making a point. Her arms are crossed, with one hand resting over the other. Her expression is friendly and inviting.\n",
            "\n",
            "\n",
            "The background is a plain, off-white or light gray, which keeps the focus firmly on the woman. The overall lighting is even and soft, without harsh shadows. The image appears to be a professionally taken portrait or product shot, possibly for advertising or a website.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#detecting emotions from the image\n",
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uJmANhuIvTtL",
        "outputId": "d3c22655-e406-4847-e6fc-b44b02d29634"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The woman in the image appears to be expressing:\n",
            "\n",
            "* **Happiness/Joy:** Her smile is genuine and bright, suggesting positive emotions.\n",
            "* **Friendliness/Approachability:**  The smile and gesture of pointing suggest she is inviting engagement or sharing information in a welcoming manner.\n",
            "* **Helpfulness/Guidance:** The pointing gesture implies she is offering assistance or directing attention to something.\n",
            "* **Confidence:** Her posture and direct gaze indicate self-assurance.\n",
            "\n",
            "\n",
            "It's important to note that these are interpretations based on visual cues.  The exact emotional state can only be known by the individual herself.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"quote.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "response = model.generate_content([\"Extract and read the text from this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "fwsfZNQlw9ag",
        "outputId": "bb9f9ef5-5af0-44bc-9ef5-c873fe34f54b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILURE is not the\n",
            "opposite of success\n",
            "it's PART OF\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"logo1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "response = model.generate_content([\"Identify the brand or company associated with this logo.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ZszZwueox4CH",
        "outputId": "31b3c474-53fa-4c58-8629-b699615cad05"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13-03-2025"
      ],
      "metadata": {
        "id": "SBpa_nKEy9uz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = \"product.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "image\n",
        "response = model.generate_content([\"What is the product in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "_jOvgzG07xhg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5e472082-8ca6-471b-c6ba-e2dd41cc2586"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.  They appear to be wireless, judging by the lack of visible wire.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar product to this one.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "k5bwPxy488Oa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "584558e8-c595-442e-8c2b-73e76531ed8f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones.  To give you the best recommendations, I need some more information.  What features are most important to you? For example:\n",
            "\n",
            "* **Budget:**  Are you looking for budget-friendly headphones, mid-range, or high-end?\n",
            "* **Noise Cancellation:** Do you need active noise cancellation (ANC)?\n",
            "* **Sound Quality:**  What type of music do you listen to? Do you prioritize bass, treble, or balanced sound?\n",
            "* **Wireless vs. Wired:** Do you prefer wireless headphones with Bluetooth, or wired headphones?\n",
            "* **Other Features:**  Are you looking for features like a microphone, water resistance, or a specific carrying case?\n",
            "\n",
            "\n",
            "Once I have this information, I can provide more specific and helpful suggestions.\n",
            "\n",
            "\n",
            "However, in the meantime, here are a few general suggestions of brands and types of headphones that are similar in style and appearance to the image:\n",
            "\n",
            "* **Sony WH-CH710N:** These are wireless headphones with noise cancellation, offering good sound quality at a mid-range price point.\n",
            "* **Audio-Technica ATH-M50x:** These are wired headphones, popular for their studio-quality sound and durability. While not wireless or noise-canceling, they offer exceptional sound for their price.\n",
            "* **Anker Soundcore Life Q30:** Another wireless option with ANC and good battery life, often available at a competitive price.\n",
            "* **JBL Tune 760NC:**  Wireless on-ear headphones with noise cancellation and a foldable design.\n",
            "\n",
            "\n",
            "These are just a few examples, and many other brands offer similar over-ear headphones.  Providing more details about your preferences will help me narrow down the options to better suit your needs.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0rz_JC__xDP",
        "outputId": "e6fa2994-342b-4009-827d-b4b2fbe80a72"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_apt import YouTubeTranscriptApi\n",
        "def get_youtube_transcript (video_url):\n",
        "  video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
        "  transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "  full_text = \" \".join([t[\"text\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "x9l-FcLsDew2",
        "outputId": "b00509b3-a516-438a-8611-d3afc150ac2c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'youtube_transcript_apt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ab5207ec2bce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myoutube_transcript_apt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_youtube_transcript\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvideo_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvideo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'youtube_transcript_apt'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "summary = summarize_video(video_transcript)\n",
        "\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WrE1oidkE-e5",
        "outputId": "31d40d4f-c7a4-4b42-ad66-6e9e332ef3b4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'video_transcript' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-51719ea6eaba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_transcript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Summary:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'video_transcript' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TaKnHJArE_Oy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}