{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYl8NwwxivkFzOnVaMDmB7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshav-reddy-27/program/blob/main/intro_gemini_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4_JOS22ctcG",
        "outputId": "af96df0d-7036-4134-debb-a899059cbdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q \"google-generative>=0.7.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYHeZ1O0cwPh",
        "outputId": "a421d644-3293-4310-efe6-383b6526a3e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement google-generative>=0.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for google-generative>=0.7.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q \"google-generativeai>=0.7.2\""
      ],
      "metadata": {
        "id": "YE-jFTZkdm4e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "print(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llNYbGdid0yK",
        "outputId": "618840f9-629e-4095-a00b-f2aa0587d74a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object list_models at 0x7ad7a6171240>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "\n",
        "response = model.generate_content(\"Please give me python code to sort a list.\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "doe1EU11hFnb",
        "outputId": "c6632f50-46bd-4e6b-97a8-11fd7e865a0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def sort_list(my_list):\n",
            "  \"\"\"Sorts a list in ascending order using the built-in sorted() function.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted.\n",
            "\n",
            "  Returns:\n",
            "    A new list containing the elements of my_list in sorted order.\n",
            "  \"\"\"\n",
            "  return sorted(my_list)\n",
            "\n",
            "# Example usage:\n",
            "unsorted_list = [5, 2, 8, 1, 9, 4]\n",
            "sorted_list = sort_list(unsorted_list)\n",
            "\n",
            "print(\"Unsorted list:\", unsorted_list)\n",
            "print(\"Sorted list:\", sorted_list)\n",
            "\n",
            "\n",
            "# In-place sorting using the .sort() method (modifies the original list)\n",
            "def sort_list_in_place(my_list):\n",
            "  \"\"\"Sorts a list in ascending order in-place using the .sort() method.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted (this list will be modified).\n",
            "  \"\"\"\n",
            "  my_list.sort()  # Modifies the list directly\n",
            "\n",
            "\n",
            "# Example usage for in-place sorting:\n",
            "unsorted_list = [5, 2, 8, 1, 9, 4]\n",
            "sort_list_in_place(unsorted_list)\n",
            "\n",
            "print(\"List after in-place sorting:\", unsorted_list)  # The original list is now sorted\n",
            "\n",
            "\n",
            "# Sorting in descending order\n",
            "def sort_list_descending(my_list):\n",
            "  \"\"\"Sorts a list in descending order using the built-in sorted() function.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted.\n",
            "\n",
            "  Returns:\n",
            "    A new list containing the elements of my_list in descending order.\n",
            "  \"\"\"\n",
            "  return sorted(my_list, reverse=True)\n",
            "\n",
            "# Example of descending order sorting\n",
            "unsorted_list = [5, 2, 8, 1, 9, 4]\n",
            "sorted_descending_list = sort_list_descending(unsorted_list)\n",
            "print(\"Sorted list in descending order:\", sorted_descending_list)\n",
            "\n",
            "\n",
            "# In-place sorting in descending order\n",
            "def sort_list_in_place_descending(my_list):\n",
            "  \"\"\"Sorts a list in descending order in-place using the .sort() method.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted (this list will be modified).\n",
            "  \"\"\"\n",
            "  my_list.sort(reverse=True)  # Modifies the list directly\n",
            "\n",
            "# Example of in-place descending order sorting\n",
            "unsorted_list = [5, 2, 8, 1, 9, 4]\n",
            "sort_list_in_place_descending(unsorted_list)\n",
            "print(\"List after in-place descending sorting:\", unsorted_list)\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Clear Function Definitions:**  The code is now organized into functions for better readability and reusability. Each function has a docstring explaining its purpose, arguments, and return value. This is crucial for maintainability.\n",
            "\n",
            "* **`sorted()` vs. `.sort()` :**\n",
            "    * `sorted(my_list)`:  This is the preferred method for most cases. It creates a *new* sorted list without modifying the original list. This is generally safer, as it avoids unintended side effects. It is a built-in function.\n",
            "    * `my_list.sort()`: This sorts the list *in-place*, meaning it modifies the original list directly. This is more efficient if you don't need to keep the original list, but it can be problematic if other parts of your code rely on the original list's order.  This is a method of the `list` object.  Crucially, `my_list.sort()` *returns `None`*.\n",
            "\n",
            "* **`reverse=True`:**  Demonstrates how to sort in descending order using both `sorted()` and `.sort()`. This is a common requirement.\n",
            "\n",
            "* **Docstrings:**  All functions have docstrings. This is good practice for documenting your code.\n",
            "\n",
            "* **Example Usage:**  Each function includes example usage, showing how to call the function and what the output will be.\n",
            "\n",
            "* **Comments:** The code is well-commented to explain the purpose of each section.\n",
            "\n",
            "* **Conciseness:**  The code is written concisely without sacrificing readability.\n",
            "\n",
            "**How to Choose:**\n",
            "\n",
            "* **Use `sorted()` if:**\n",
            "    * You need to preserve the original list.\n",
            "    * You're working with an immutable sequence (e.g., a tuple), as `sorted()` can be used to create a new, sorted list from it.\n",
            "\n",
            "* **Use `my_list.sort()` if:**\n",
            "    * You don't need to keep the original list.\n",
            "    * You are concerned about performance and want to avoid creating a new list (but be mindful of potential side effects).\n",
            "    * You are certain that modifying the original list is safe and won't break other parts of your code.\n",
            "\n",
            "**Important Notes:**\n",
            "\n",
            "* **Mutability:** Lists are mutable (can be changed), while tuples are immutable (cannot be changed). The `.sort()` method *only* works on mutable lists.  `sorted()` works on any iterable.\n",
            "* **Algorithms:** Python's `sorted()` and `.sort()` methods use Timsort, a hybrid sorting algorithm derived from merge sort and insertion sort.  It's highly efficient for a wide range of data. You generally don't need to worry about implementing your own sorting algorithm unless you have very specific performance requirements.\n",
            "* **Custom Sorting:**  Both `sorted()` and `.sort()` allow you to provide a `key` function for custom sorting (e.g., sorting a list of objects based on a specific attribute).\n",
            "```python\n",
            "#Example for custom sorting with lambda functions\n",
            "\n",
            "people = [\n",
            "    {\"name\": \"Alice\", \"age\": 30},\n",
            "    {\"name\": \"Bob\", \"age\": 25},\n",
            "    {\"name\": \"Charlie\", \"age\": 35}\n",
            "]\n",
            "\n",
            "# Sort by age:\n",
            "sorted_by_age = sorted(people, key=lambda person: person[\"age\"])\n",
            "print(\"Sorted by age:\", sorted_by_age)\n",
            "\n",
            "# Sort by name:\n",
            "sorted_by_name = sorted(people, key=lambda person: person[\"name\"])\n",
            "print(\"Sorted by name:\", sorted_by_name)\n",
            "```\n",
            "\n",
            "This comprehensive response provides you with everything you need to sort lists in Python effectively.  Choose the method that best suits your specific needs and coding style. Always remember to consider the implications of modifying a list in-place.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "PgnVNdkkjhS8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What is large language model?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y7b9ekrHkPWf",
        "outputId": "1fd55a34-9f12-4c2f-f913-e8013704a45d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a massive dataset of text and code to understand and generate human-like text. Think of it as a really, really smart parrot that can not only repeat what it's heard, but also understand the nuances and relationships between words, and use that understanding to create new and original content.\n",
            "\n",
            "Here's a breakdown of what makes them special:\n",
            "\n",
            "*   **Large:** The \"large\" in LLM refers to the sheer size of the model, measured in terms of the number of parameters it has. Parameters are essentially the variables the model learns during training. Models with billions or even trillions of parameters can capture more complex patterns and relationships in the data.\n",
            "\n",
            "*   **Language:** LLMs are specifically designed to work with human language. They are trained to understand grammar, vocabulary, context, and even different writing styles.\n",
            "\n",
            "*   **Model:** LLMs are based on neural networks, a type of machine learning algorithm inspired by the structure of the human brain. These networks consist of interconnected nodes that process and transform information.\n",
            "\n",
            "**Key Characteristics and Capabilities:**\n",
            "\n",
            "*   **Text Generation:**  Can generate various types of text, including articles, stories, poems, code, and scripts.\n",
            "*   **Text Completion:** Can complete sentences or paragraphs based on a given prompt.\n",
            "*   **Text Summarization:** Can condense long documents into shorter, more concise summaries.\n",
            "*   **Translation:** Can translate text between different languages.\n",
            "*   **Question Answering:** Can answer questions based on the information it has been trained on.\n",
            "*   **Code Generation:** Can generate code in various programming languages.\n",
            "*   **Dialogue/Chatbots:** Can engage in conversations and provide responses to user queries.\n",
            "*   **Understanding Context:** Can understand the context of a conversation or a piece of text, and respond accordingly.\n",
            "*   **Following Instructions:** Can follow specific instructions and generate text that adheres to those guidelines.\n",
            "\n",
            "**How They Work (Simplified):**\n",
            "\n",
            "1.  **Training:** LLMs are trained on enormous datasets of text and code. This data is used to teach the model the relationships between words and phrases, and how to generate coherent and grammatically correct text.\n",
            "\n",
            "2.  **Prediction:** When given a prompt or input text, the LLM uses its training to predict the most likely next word or sequence of words. It does this by considering the context of the input and the patterns it has learned from the training data.\n",
            "\n",
            "3.  **Generation:** The LLM continues to predict the next word until it has generated a complete sentence, paragraph, or even a whole document.\n",
            "\n",
            "**Examples of LLMs:**\n",
            "\n",
            "*   **GPT-3, GPT-4 (OpenAI):** Powerful and versatile models known for their text generation capabilities.\n",
            "*   **LaMDA (Google):**  Focuses on conversational AI and creating more natural-sounding dialogue.\n",
            "*   **BERT (Google):**  Excellent for understanding the context of text and performing tasks like sentiment analysis.\n",
            "*   **Llama 2 (Meta):** An open-source LLM designed to be accessible for research and development.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "LLMs are used in a wide range of applications, including:\n",
            "\n",
            "*   **Chatbots and virtual assistants**\n",
            "*   **Content creation and marketing**\n",
            "*   **Customer service and support**\n",
            "*   **Education and research**\n",
            "*   **Software development**\n",
            "*   **Machine translation**\n",
            "\n",
            "**Limitations:**\n",
            "\n",
            "*   **Bias:** LLMs can inherit biases from the data they are trained on, leading to unfair or discriminatory outputs.\n",
            "*   **Lack of Common Sense:**  While they can generate impressive text, LLMs don't always have a real-world understanding of the topics they are discussing.\n",
            "*   **Hallucination:** LLMs can sometimes generate information that is incorrect or nonsensical, known as \"hallucinations.\"\n",
            "*   **Computational Cost:** Training and running LLMs can be computationally expensive, requiring significant resources.\n",
            "*   **Ethical Concerns:** Concerns regarding misuse, disinformation, and potential impact on the job market.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Large language models are sophisticated AI systems capable of understanding and generating human-like text. They are revolutionizing various industries and have the potential to transform the way we interact with computers and information. However, it's important to be aware of their limitations and ethical considerations as they continue to evolve.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Give me python code to find the factorial of a given number\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_EXPKq9nHdz",
        "outputId": "8048fef7-ac9c-4350-8305-1207e4d5c9a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def factorial(n):\n",
            "  \"\"\"\n",
            "  Calculates the factorial of a non-negative integer.\n",
            "\n",
            "  Args:\n",
            "    n: A non-negative integer.\n",
            "\n",
            "  Returns:\n",
            "    The factorial of n (n!), or 1 if n is 0.\n",
            "    Returns None if n is negative.\n",
            "  \"\"\"\n",
            "  if n < 0:\n",
            "    return None  # Factorial is not defined for negative numbers\n",
            "  elif n == 0:\n",
            "    return 1  # Base case: factorial of 0 is 1\n",
            "  else:\n",
            "    result = 1\n",
            "    for i in range(1, n + 1):\n",
            "      result *= i\n",
            "    return result\n",
            "\n",
            "# Example usage:\n",
            "number = 5\n",
            "result = factorial(number)\n",
            "\n",
            "if result is not None:\n",
            "  print(f\"The factorial of {number} is {result}\")\n",
            "else:\n",
            "  print(f\"Cannot calculate the factorial of {number} because it is negative.\")\n",
            "\n",
            "\n",
            "# Recursive approach (alternative)\n",
            "\n",
            "def factorial_recursive(n):\n",
            "  \"\"\"\n",
            "  Calculates the factorial of a non-negative integer using recursion.\n",
            "\n",
            "  Args:\n",
            "    n: A non-negative integer.\n",
            "\n",
            "  Returns:\n",
            "    The factorial of n (n!), or 1 if n is 0.\n",
            "    Returns None if n is negative.\n",
            "  \"\"\"\n",
            "  if n < 0:\n",
            "    return None\n",
            "  elif n == 0:\n",
            "    return 1\n",
            "  else:\n",
            "    return n * factorial_recursive(n-1) # Recursive call\n",
            "\n",
            "\n",
            "# Example usage of recursive version:\n",
            "number = 6\n",
            "result_recursive = factorial_recursive(number)\n",
            "\n",
            "if result_recursive is not None:\n",
            "  print(f\"The factorial of {number} (using recursion) is {result_recursive}\")\n",
            "else:\n",
            "  print(f\"Cannot calculate the factorial of {number} (using recursion) because it is negative.\")\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Error Handling:**  The code now explicitly handles negative input.  The factorial of a negative number is *not* defined.  Returning `None` (or raising a `ValueError` exception) is the correct way to signal this.  Printing an error message to the console is also good practice.  The user is clearly informed why the factorial can't be calculated.\n",
            "* **Base Case:** The code correctly handles the base case of `n == 0`.  The factorial of 0 is defined as 1. This is *essential* for both the iterative and recursive versions.\n",
            "* **Iterative Approach (Main Solution):** The iterative approach is generally preferred for factorial calculations because it avoids the risk of stack overflow errors that can occur with deep recursion for large values of `n`.  It's also often slightly faster.\n",
            "* **Recursive Approach (Alternative):**  The recursive approach is included as an alternative for demonstration purposes.  While elegant, be mindful of its potential for stack overflow.  The recursive version is commented separately.\n",
            "* **Clearer Comments:**  The comments are more comprehensive, explaining the purpose of the function, the arguments, and the return value.\n",
            "* **`None` Return Value:** Returning `None` to indicate an error is better than printing a message directly from the function. This allows the calling code to handle the error in a way that's appropriate for the application (e.g., logging, displaying an error message in a GUI, etc.).  The calling code *then* prints the error message to the user, as shown in the example usage.\n",
            "* **Example Usage:**  The example usage clearly demonstrates how to call the function and how to handle the potential `None` return value if the input is invalid.  Separate example usage for the recursive version is also included.\n",
            "* **Efficiency:** The iterative approach is slightly more efficient than the recursive approach.\n",
            "\n",
            "How to Run the Code:\n",
            "\n",
            "1.  **Save:** Save the code as a Python file (e.g., `factorial.py`).\n",
            "2.  **Run:** Open a terminal or command prompt, navigate to the directory where you saved the file, and run it using `python factorial.py`.  The output will be printed to the console.\n",
            "\n",
            "This revised response provides a robust, well-documented, and practical solution for calculating factorials in Python, addressing potential errors and offering both iterative and recursive implementations. It emphasizes proper error handling and clear communication of the results to the user.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FgsSzgMxm9jF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "response = client.models.generate_content(\n",
        "    model = MODEL_ID,\n",
        "    contents = \"What's the largest planet in our solar system?\"\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "e_7uUgvwljjL",
        "outputId": "2b707257-ecf3-4242-988e-3c595c0be071"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The largest planet in our solar system is **Jupiter**.\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "6dmYVJbimykW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11=03=2025"
      ],
      "metadata": {
        "id": "wfMxfZKjpCZD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "TRd4gPrYsMsN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "nExXjBRJsRNn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "import pathlib\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "IMG = \"https://storage.googleapis.com/generativeai-downloads/data/jetpack.png\" # @param {type: \"string\"}\n",
        "\n",
        "img_bytes = requests.get(IMG).content\n",
        "\n",
        "img_path = pathlib.Path('jetpack.png')\n",
        "\n",
        "img_path.write_bytes(img_bytes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vmRNEcBsVaJ",
        "outputId": "ea14b865-0ddc-424b-b6f5-c71d11b4fa17"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1567837"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRJLTbqQo6wC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "\n",
        "  text = text.replace('•', '  *')\n",
        "\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "a6cMY-U_onlI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img = PIL.Image.open('image1.jpg')\n",
        "\n",
        "img\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n",
        "\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "vj_659PlrBU-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "0XtgZC4DtPZH",
        "outputId": "6c4608bb-dcd1-4272-d7d6-d1aa8dd066f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## My Meal Prep Journey: From Chaos to Colorful Containers!\n> \n> Look at this gorgeousness!  These aren't just any lunchboxes; these are my meticulously crafted masterpieces of meal prepping!  Each container is packed with a healthy and delicious serving of teriyaki chicken, fluffy white rice, vibrant roasted carrots and peppers, and a generous helping of broccoli.  Seriously, it's a flavor explosion in every bite, and all ready to go in minutes!\n> \n> My journey into meal prepping wasn't always this picture-perfect.  Let's just say it started with a lot of good intentions and a whole lot of takeout containers filled with questionable leftovers. I'd spend my Sundays completely overwhelmed, trying to cook enough food for the week only to end up eating the same boring meal for days and throwing away half-spoiled produce.\n> \n> But I was determined! I started small.  One or two recipes a week, focusing on simple, healthy options I actually enjoyed.  Gradually, I found the perfect balance of preparation and variety. Now, my Sundays are a calm, organized production line, ending with a fridge and freezer full of delicious, healthy meals ready for the week ahead.  The best part? No more last-minute frantic searches for something to eat.  This is freedom, my friends!\n> \n> This teriyaki chicken and veggie bowl is a recent favorite – quick to prepare, packed with protein and nutrients, and tastes absolutely divine.  Want to know the secret to my success?  Planning!  I create a menu, make a shopping list, and then batch cook as much as possible.  Simple tweaks like that transformed my meal prep from a dreaded chore to a therapeutic activity that saves time and money. And hey, these cute containers definitely help too!\n> \n> So, what's your favorite meal prep trick?  Share your tips in the comments below!\n"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = \"girl.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "response = model.generate_content([\"Describe this image in detail.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "OAFgdvsetzQs",
        "outputId": "4f00957e-4288-4332-cb94-84ed743d8e89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly brown hair. \n",
            "\n",
            "\n",
            "She is smiling and pointing to her side with her right index finger. Her expression is friendly and engaging. She appears to be of South Asian descent. \n",
            "\n",
            "\n",
            "She's wearing a teal-colored three-quarter-sleeved top or kurta with a subtle gold print or pattern. The pattern is small and fairly evenly distributed across the garment. The neckline is a simple, modest V-neck. Her arms are folded across her body, with one arm slightly bent to emphasize her pointing gesture.\n",
            "\n",
            "\n",
            "The background is plain white, keeping the focus entirely on the woman. The lighting is soft and even, minimizing harsh shadows. The overall impression is one of a friendly, approachable woman, perhaps gesturing towards something off-camera or making a suggestion.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#detecting emotions from the image\n",
        "response = model.generate_content([\"What emotions can you detect in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "uJmANhuIvTtL",
        "outputId": "1336b762-84c9-46cb-b606-e09dc9bbca7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The woman in the image appears to be expressing happiness, confidence, and helpfulness.  Her smile is genuine, and her gesture of pointing suggests she's guiding or informing the viewer.  There's no indication of negative emotions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"quote.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "response = model.generate_content([\"Extract and read the text from this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "fwsfZNQlw9ag",
        "outputId": "4b617f4d-7b58-4d41-aa3e-f7ab1626ad97"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the text from the image:\n",
            "\n",
            "FAILURE is not the\n",
            "opposite of success\n",
            "it's PART OF\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"logo1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "response = model.generate_content([\"Identify the brand or company associated with this logo.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ZszZwueox4CH",
        "outputId": "87336daa-775f-4968-bef6-e0bf209f7940"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBpa_nKEy9uz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}